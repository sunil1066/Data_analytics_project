setwd("~/R/csv/wiki")
wiki= read.csv("wiki.csv", stringAsFactor=FALSE)
wiki= read.csv("wiki.csv", stringsAsFactors=FALSE)
str(wiki)
wiki$Vandal = as.factor(wiki$Vandal)
str(wiki)
table(wiki$Vandal)
library(tm)
library(SnowballC)
corpusAdded= Corpus(VectorSource(wiki$Added))
corpusAdded
corpusAdded[[1]]
corpusAdded= tm_map(corpusAdded, removeWords, stopwords("english"))
corpusAdded[[1]]
corpusAdded= tm_map(corpusAdded, stemDocument
)
corpusAdded[[1]]
dtmAdded= DocumentTermMatrix(corpusAdded)
dtmAdded
length(stopwords("english"))
findFreqTerms(corpusAdded, lowfreq=20)
sparse= removeSparseTerms(corpusAdded, 0.997)
sparse= removeSparseTerms(dtmAdded, 0.997)
sparse
wordsAdded= as.data.frame(as.matrix(sparse))
wordsAdded
colnames(wordsAdded)= paste("A",colnames(wordsAdded))
colnames(wordsAdded)
names(wiki)
str(corpus)
str(wiki)
corpus1= Corpus(VectorSource(wiki$Removed))
corpus1= tm_map(corpus1, removeWords, stopwords("english"))
corpus1= tm_map(corpus1, stemDocument)
dtm1= DocumentTermMatrix(corpus1)
dtm1
sparse1= removeSparseTerms(dtm1, 0.997)
sparse1
wordsRemoved= as.data.frame(as.matrix(sparse1))
wordsRemoved
colnames(wordsRemoved)= paste("R", colnames(wordsRemoved))
colnames(wordsRemoved)
ncol(wordsRemoved)
wikiWords= cbind(wordsAdded, wordsRemoved)
wikiWords
names(wiki)
names(wikiwords)
names(wikiWords)
names(wiki)
wikiWords$Vandal = wiki$Vandal
str(wikiWords)
set.seed(123)
library(caTools)
split= sample.split(wikiWords$Vandal, SplitRatio=0.7)
train= subset(wikiWords, split==TRUE)
test= subset(wikiWords, split==FALSE)
table(train$Vandal)
table(test$Vandal)
618/(1163)
library(rpart)
library(rpart.plot)
cart= rpart(Vandal ~ . , data=train, method="class")
prp(cart)
pcart= predict(cart, newdata=test, type="class")
table(test$Vandal, pcart)
(618+12)/nrow(test)
table(train$Vandal, cart)
table(train$Vandal, pcart)
table(train$Vandal)
cart
str(cart)
pcart
str(pcart)
table(train$Vandal)
table(train$Vandal, cart)
str(cart)
summary(cart)
pcart1= predict(cart, type="class")
table(train$Vandal, pcart1)
(1443+33)/nrow(train)
wikiWords2= wikiWords
wikiWords2$HTTP = ifelse(grepl("http",wiki$Added, fixed=TRUE),1,0)
str(wikiWords2)
summary(wikiWords2)
str(wikiWords2$HTTP)
table(wikiWords2$HTTP)
train2= subset(wikiWords2, split==TRUE)
test2= subset(wikiWords2, split==FALSE)
cart2= rpart(Vandal ~ . , data=train2, method=)
cart2= rpart(Vandal ~ . , data=train2, method="class")
pcart2= predict(cart2, newdata=test2, type="class")
table(wikiWords2$Vandal, pcart2)
table(test2$Vandal, pcart2)
(609+57)/nrow(test2)
dtmadded
dtmAdded
dtm1
wikiWords2$NumWordsAdded= rowSums(as.matrix(dtmAdded))
str(wikiWords2$NumWordsAdded)
str(wikiWords2)
wikiWords2$NumWordsRemoved= rowSums(as.matrix(dtm1))
str(wikiWords2$NumWordsRemoved)
summary(wikiWords2$NumWordsRemoved)
summary(wikiWords2$NumWordsAdded)
names(wikiWords2)
str(wiki)
table(wikiWords2$NumWordsAdded)
table(wikiWords2$NumWordsAdded, wikiWords2$NumWordsRemoved)
table(wikiWords2$NumWordsAdded)
str(wikiWords2$NumWordsAdded)
sum(wikiWords2$NumWordsAdded)
sum(wikiWords2$NumWordsRemoved)
(15698-13616)/(15698)
str(wikiWords2)
names(wikiWords2)
wikiWords3= wikiWords2
wikiWords3$Minor= wiki$Minor
wikiWords3$Loggedin= wiki$Loggedin
train3 = subset(wikiWords3, split==TRUE)
test3= subset(wikiWords3, split==FALSE)
cart3= rpart(Vandal ~ . , data=train3, method="class")
pcart3= predict(cart3, newdata=test3, type="class")
table(wikiWords3$Vandal, pcart3)
table(test3$Vandal, pcart3)
(595+241)/nrow(test3)
prp(cart3)
nchar()
nchar(sunil)
nchar(wiki)
